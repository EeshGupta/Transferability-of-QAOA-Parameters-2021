{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#################\n",
    "# My notebook issues\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "sys.path.append('home/egupta/.local/bin')\n",
    "\n",
    "##############\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import networkx as nx\n",
    "import csv \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "##qtensor imports\n",
    "import qtensor\n",
    "from qtensor import QAOA_energy\n",
    "from qtensor import parameter_optimization as popt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "Use averaging technique for both graphs and subgraphs to generate pairs plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_all(d1, d2, draw=False):\n",
    "    # returns a list of subgraphs of all graphs with nodes of the central edge having degree d1 and d2\n",
    "    A = np.zeros((d1 + d2, d1 + d2))\n",
    "    A[d1 + 1:, d1] = 1\n",
    "    A[:d1 - 1, d1 - 1] = 1\n",
    "    A[d1 - 1, :d1 - 1] = 1\n",
    "    A[d1, d1 + 1:] = 1\n",
    "    A[d1, d1 - 1] = 1\n",
    "    A[d1 - 1, d1] = 1\n",
    "    \n",
    "    g = nx.from_numpy_matrix(np.array(A))\n",
    "\n",
    "    g_list = [g]\n",
    "    for i in range(min(d1, d2) - 1):\n",
    "        g = g_list[i]\n",
    "        g_list.append(nx.contracted_nodes(g, i, i + d1 + 1))\n",
    "    # relabel center edge as (0, 1)\n",
    "    for i, g in enumerate(g_list):\n",
    "        g_list[i] = qtensor.tools.lightcone_orbits.relabel_edge_first(g, (d1 - 1, d1))\n",
    "        if draw:\n",
    "            nx.draw_kamada_kawai(g)\n",
    "            plt.show()\n",
    "    return g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating all subgraphs first \n",
    "d_min = 1\n",
    "d_max = 6\n",
    "g_all = []\n",
    "for i in range(d_min, d_max + 1):\n",
    "    for j in range(i, d_max + 1):\n",
    "        g_sub_ij = sub_all(i, j, draw=True)\n",
    "        g_all += g_sub_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"/home/egupta/Documents/Eesh's Experiments/Transferability Matrices/transferability_matrix_random_subgraphs_6.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranf_mat_orig = np.loadtxt(file1).reshape(56,56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(tranf_mat_orig)#, index=Index, columns=Cols)\n",
    "sns.heatmap(df, annot=False, cmap=\"RdBu\")\n",
    "plt.title(\"Original Transf Mat\")\n",
    "plt.ylabel('Donor')\n",
    "plt.xlabel('Acceptor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranf_mat = tranf_mat_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying SUbgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(g, subgraphs):\n",
    "    \"\"\"\n",
    "    finds index of subgraph g is isomorphic with\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i<len(subgraphs):\n",
    "        if nx.is_isomorphic(g, subgraphs[i]):\n",
    "            return i\n",
    "        i+=1\n",
    "    print('error: could not find subgraph')\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subgraphs(G):\n",
    "  '''\n",
    "  Input: A graph G\n",
    "  Output: A dictionary containg subgraphs and their frequency in G\n",
    "  '''\n",
    "  edges_done = []\n",
    "  subgraphs = {}\n",
    "\n",
    "  vertices = G.nodes\n",
    "  for v1 in vertices:\n",
    "    ######print('----------------------------------------')\n",
    "    ######print('Parent checking for vertex ' +str(v1) )\n",
    "    neighbors = nx.all_neighbors(G,v1)\n",
    "    ######print(neighbors)\n",
    "    #iterate over edges\n",
    "    for v2 in neighbors:\n",
    "      ######print('Childchecking for vertex ' +str(v2) )\n",
    "      ##if already there\n",
    "      if (v1,v2) in edges_done:\n",
    "        #######print('Already looked at')\n",
    "        continue\n",
    "      ##add if not there\n",
    "      else:\n",
    "        ######print('Not looked at')\n",
    "        edges_done.append((v1,v2))\n",
    "        edges_done.append((v2,v1))\n",
    "      \n",
    "      neighbors1 = nx.all_neighbors(G,v1)\n",
    "      neighbors2 = nx.all_neighbors(G, v2)\n",
    "\n",
    "      subg_edge_set = []\n",
    "      for v in neighbors1:\n",
    "        #######print(v)\n",
    "        edge = (v1, v)\n",
    "        subg_edge_set.append(edge)\n",
    "\n",
    "      for v in neighbors2:\n",
    "        ######print(v)\n",
    "        if v is not v1:\n",
    "          edge = (v2, v)\n",
    "          subg_edge_set.append(edge)\n",
    "\n",
    "      ##creating the subgraph\n",
    "      H = G.edge_subgraph(subg_edge_set)\n",
    "\n",
    "      ##check if isomorphic with any other subgraphs\n",
    "      iso = False\n",
    "      subgraphs_arr = subgraphs.keys()\n",
    "      for subgraph in subgraphs_arr:\n",
    "        if nx.is_isomorphic(H, subgraph):\n",
    "          #######print('is isomorphic')\n",
    "          subgraphs[subgraph] +=1\n",
    "          iso = True\n",
    "          break\n",
    "      if iso == False:\n",
    "        #######print('---------------Adding a subgraph--------------------')\n",
    "        subgraphs[H] = 1\n",
    "        ######print(subgraphs)\n",
    "  return subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(G1, G2, subgraphs = g_all, tranf_mat = tranf_mat):\n",
    "  \"\"\"\n",
    "  Compute similarity metric between 2 graphs\n",
    "  \"\"\"\n",
    "  sub_g1_dict = find_subgraphs(G1)\n",
    "  sub_g2_dict = find_subgraphs(G2)\n",
    "  sub_g1 = sub_g1_dict.keys()\n",
    "  sub_g2 = sub_g2_dict.keys()\n",
    "  metric = 0\n",
    "  total_arrows = 0\n",
    "\n",
    "  for donor in sub_g1:\n",
    "    for acceptor in sub_g2:\n",
    "      arrows = sub_g1_dict[donor]*sub_g2_dict[acceptor]\n",
    "      i = find_index(donor, subgraphs)\n",
    "      j = find_index(acceptor, subgraphs)\n",
    "      metric+= arrows*tranf_mat[i,j]\n",
    "      total_arrows += arrows\n",
    "  metric = metric/total_arrows\n",
    "  return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_energy(results):\n",
    "    \"\"\"\n",
    "    Given multiple local optima, find the max\n",
    "    \"\"\"\n",
    "    energies = []\n",
    "    #print(results)\n",
    "    for i in range(len(results)):\n",
    "        energies.append(results[i][2])\n",
    "    return max(energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtensor import QAOA_energy\n",
    "\n",
    "def actual_sim(G1, G2,g1_results, g2_results):\n",
    "    \"\"\"\n",
    "    Returns similarity between two graphs computed directly\n",
    "    \"\"\"\n",
    "    #Now computing similarity\n",
    "    sim = 0\n",
    "    acc_max_energy = find_max_energy(g2_results)\n",
    "    n= len(g1_results)\n",
    "  \n",
    "    for i in range(n):\n",
    "        donor_gamma = g1_results[i][0]\n",
    "        donor_beta = g1_results[i][1]\n",
    "\n",
    "        transf_energy = QAOA_energy(G2, [donor_gamma], [donor_beta])\n",
    "        #print(transf_energy)\n",
    "        sim += transf_energy/acc_max_energy\n",
    "    return sim/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_similarity(G1, subgraphs = g_all, tranf_mat = tranf_mat):\n",
    "  \"\"\"\n",
    "  Compute subgraph similarity metric within a graph\n",
    "  \"\"\"\n",
    "  sub_g1_dict = find_subgraphs(G1)\n",
    "  sub_g1 = sub_g1_dict.keys()\n",
    "  metric = 0\n",
    "  total_arrows = 0\n",
    "\n",
    "  for donor in sub_g1:\n",
    "    for acceptor in sub_g1:\n",
    "      if (nx.is_isomorphic(donor, acceptor) is False):\n",
    "        arrows = sub_g1_dict[donor]*sub_g1_dict[acceptor]\n",
    "        i = find_index(donor, subgraphs)\n",
    "        j = find_index(acceptor, subgraphs)\n",
    "        metric+= arrows*tranf_mat[i,j]\n",
    "        total_arrows += arrows\n",
    "  if total_arrows == 0:\n",
    "      return 1\n",
    "  else:\n",
    "      metric = metric/total_arrows\n",
    "      return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"New110Distinct20NodeRandomGraphs.txt\")\n",
    "file3 = open(\"New110Distinct20NodeRandomGraphsData.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_data = list(np.loadtxt(file3).reshape(110,20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_list = list(np.loadtxt(file2).reshape(110,20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mats_to_graphs(mat_list):\n",
    "  \"\"\"\n",
    "  Given list of adjaceny matrix repr of graphs, converts to actual graphs\n",
    "  \"\"\"\n",
    "  g_list = []\n",
    "  for mat in mat_list:\n",
    "    arr = np.array(mat)\n",
    "    G = nx.convert_matrix.from_numpy_matrix(arr)\n",
    "    g_list.append(G)\n",
    "  return g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_list = mats_to_graphs(mat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "actual_sim(g_list[i], g_list[j],g_data[i], g_data[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = [i for i in range(44,66,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptors = [i for i in range(110)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_general(A, B, graphs = g_list,g_results = g_data):\n",
    "  \"\"\"\n",
    "  A, B are sets of indices for graphs between which we have to establish tranferability\n",
    "  \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  a_ss= []\n",
    "  s_ss = []\n",
    "  labels = []\n",
    "  #datas = []\n",
    "\n",
    "\n",
    "  #first tackling A-B graphs\n",
    "  for i in A:\n",
    "    donor = graphs[i]\n",
    "    donor_results = g_results[i]\n",
    "    donor_sim = mutual_similarity(G1 = donor)\n",
    "    for j in B:\n",
    "    \n",
    "      acceptor = graphs[j]\n",
    "      acceptor_results = g_results[j]\n",
    "      acceptor_sim = mutual_similarity(G1 = acceptor)\n",
    "      #acc_max_energy = max_energies[j]\n",
    "\n",
    "      a_sim = float(actual_sim(donor, acceptor, donor_results, acceptor_results))\n",
    "      s_sim = similarity(donor, acceptor)\n",
    "      a_ss.append(a_sim)\n",
    "      s_ss.append(s_sim)\n",
    "      # deg1 = graph_index_to_even_deg_nodes(i)\n",
    "      # deg2 = graph_index_to_even_deg_nodes(j)\n",
    "      # labels.append(str(deg1) + \"->\"+str(deg2))\n",
    "      \n",
    "      xs.append(donor_sim)\n",
    "      ys.append(acceptor_sim)\n",
    "      # deg1 = graph_index_to_even_deg_nodes(i)\n",
    "      # deg2 = graph_index_to_even_deg_nodes(j)\n",
    "      # data = [[[x,y]], str(deg1)+'<->'+str(deg2)]\n",
    "      # datas.append(data)\n",
    "        \n",
    "  return [xs,ys,a_ss, s_ss]#, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "results = run_general(donors, acceptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"Similarity110DistinctSep19Pt3.txt\", \"w\")\n",
    "for row in results:\n",
    "    np.savetxt(a_file, row)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
